# Copy this file to .env and fill in your API keys
# Do NOT commit .env to version control

# ============================================================================
# PROVIDER CONFIGURATION
# ============================================================================

# Choose which provider to use (optional, auto-detected if not set)
# Options: "anthropic", "openai", "local"
# PROVIDER=anthropic

# ============================================================================
# ANTHROPIC (Claude) - RECOMMENDED
# ============================================================================

# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-...

# Optional: Choose a specific model
# Available models: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
# Default: claude-3-opus-20240229
# MODEL=claude-3-sonnet-20240229

# ============================================================================
# OPENAI (GPT-4/GPT-5)
# ============================================================================

# Get your API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-...

# Optional: Choose a specific model
# Available models: gpt-4, gpt-4-turbo, gpt-4-32k, gpt-5 (if available)
# Default: gpt-4
# MODEL=gpt-4-turbo

# ============================================================================
# LOCAL OLLAMA
# ============================================================================

# Optional: Specify Ollama host (default: http://localhost:11434)
# OLLAMA_HOST=http://localhost:11434

# Optional: Choose a specific model
# Available models: llama2, mistral, neural-chat, codeup, etc.
# See: https://ollama.ai/library
# Default: llama2
# MODEL=mistral

# ============================================================================
# ADVANCED OPTIONS
# ============================================================================

# Maximum tokens in a response (default: 8192)
# MAX_TOKENS=8192

# API timeout in seconds (default: 120)
# API_TIMEOUT_SECS=120

# ============================================================================
# DEVELOPMENT
# ============================================================================

# Enable debug logging (default: false)
# RUST_LOG=debug

# ============================================================================
# QUICK START EXAMPLES
# ============================================================================

# Example 1: Use Anthropic (fastest to get started)
# ANTHROPIC_API_KEY=sk-ant-...
# MODEL=claude-3-sonnet-20240229

# Example 2: Use OpenAI GPT-4
# OPENAI_API_KEY=sk-...
# MODEL=gpt-4-turbo

# Example 3: Use local Ollama
# OLLAMA_HOST=http://localhost:11434
# MODEL=mistral
